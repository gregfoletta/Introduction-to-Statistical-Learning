<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Conceptual</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>



<!-- MathJax scripts -->
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Conceptual</h1>

<h2>1)</h2>

<p><em>We perform best subset, forward stepwise, and backward stepwise selection on a single data set. For each approach, we obtain \(p + 1\) models, containing \(0, 1, 2,\ldots,p\) predictors. Explain your answers:</em></p>

<h3>a)</h3>

<p><em>Which of the three models with k predictors has the smallest training RSS?</em></p>

<p>As the best-subset fits every combination of predictors, it will have the smallest training RSS.</p>

<h3>b)</h3>

<p><em>Which of the three models with k predictors has the smallest test RSS?</em></p>

<p>Best subset may have the smallest test RSS because it considers more models. However it also may be overfitting the training data, and one of the other models may find a better model for the test data.</p>

<h3>c)</h3>

<p><em>True or False:</em></p>

<h4>i)</h4>

<p><em>The predictors in the \(k\)-variable model identified by forward stepwise are a subset of the predictors in the \((k+1)\) variable model identified by forward stepwise selection.</em></p>

<p>In each step, forward stepwise augments with one additional predictor, hence the statement is <strong>true</strong>.</p>

<h4>ii)</h4>

<p><em>The predictors in the k-variable model identified by backward stepwise are a subset of the predictors in the (k + 1) variable model identified by backward stepwise selection.</em></p>

<p>In each step the backward stepwise the least useful predictor is removed, hence the answer is <strong>true</strong>.</p>

<h4>iii)</h4>

<p><em>The predictors in the k-variable model identified by backward stepwise are a subset of the predictors in the (k + 1) variable model identified by forward stepwise selection.</em></p>

<p>Forward and backward stepwise are independent functions, thus the above statement is <strong>false</strong>.</p>

<h4>iv)</h4>

<p><em>The predictors in the k-variable model identified by forward stepwise are a subset of the predictors in the (k +1)-variable model identified by backward stepwise selection.</em></p>

<p><strong>False</strong>.</p>

<h4>v)</h4>

<p><em>The predictors in the k-variable model identified by best subset are a subset of the predictors in the (k + 1)-variable model identified by best subset selection.</em></p>

<p>Best subset chooses the best model for each \(k\), therefore the above statement is <strong>false</strong>.</p>

<h2>2)</h2>

<p><em>For parts (a) through &copy;, indicate which of i. through iv. is correct. Justify your answer.</em></p>

<h3>a)</h3>

<p><em>The lasso, relative to least squares, is:</em></p>

<p>Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.</p>

<p>The lasso reduces the flexibility, decreasing the variance and increasing the bias.</p>

<h3>b)</h3>

<p><em>The ridge regression, relative to least squares, is:</em></p>

<p>Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.</p>

<p>Same as a)</p>

<h3>c)</h3>

<p><em>Non-linear methods, relative to least squares, are:</em></p>

<p>More flexible, and will give improves accuracy when its increase in variance is less than it&#39;s decrease in bias.</p>

<h2>3)</h2>

<p>*Suppose we estimate the regression coefficients in a linear regression model by minimizing:</p>

</body>

</html>
