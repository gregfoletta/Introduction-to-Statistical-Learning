# Chapter 3 - Notes

## 3.1 - Simple Linear Regression

A simple linear regression predicts a response `Y` based on a single predictor variable `X`. 
```
Y ≈ β_0 + β_1X
```

Once we have training data to produce estimates for the coefficients, we can predict values by computing:
```
ŷ = β̂ 0 + β̂ 1x
```

### 3.1.1 - Estimating Coefficients

The goal is to obtain coefficients such that the linear model fits the data well - i.e. as close as possible to the data points. The most common approach involves minimising the **least squares** criterion.

We let `e_i = y_i − ŷ_i`, which represents the *i*th **residual**. The **residual sum of squares** or **RSS** is the sum of the squares of each of these residuals.

An example in R - we generate some data and calculate the residual sum of squares.

```{r 3.1.1 setup, message = F}
library(tidyverse)
```
```{r 3.1.1_1}
set.seed(1)
y_i <- rnorm(10)
y_hat_i <- rnorm(10)
(RSS = sum((y_i - y_hat_i)^2))
```

With some calculus, the minimiser for `β̂ 1x` is The sum of the difference between `x` and the mean of `x` times by the difference between `y` and the mean of `y`, all divided by the sum of the square of the difference between `x` and the mean of `x`.

```{r 3.1.1_2}
set.seed(1)
x <- rnorm(10)
y <- rnorm(10)
beta_hat_1 <- sum( (x - mean(x)) * (y - mean(y)) ) / sum( (x - mean(x))^2 )
beta_hat_0 <- mean(y) - (beta_hat_1 * mean(x))

beta_hat_0
beta_hat_1
```

### 3.1.2 - Assessing the Accuracy of the Estimates

We take the analogy of μ̂, the **sample mean** being an estimate for μ, the **population mean**. The average sample mean over many data sets will be close to the population mean. In the code below, we create a population of 1,000,000 random variables, with very large standard deviation of 10,000. We see the mean is 10.46.

We then take 200 samples of 100 of the population, and calculate the mean for each sample. We see that each mean can be a very long way away from the real mean of 10.046.

We then take the mean of all of the sample means. We see this sample mean is 9.99, which is very close to the population mean.

```{r 3.1.2_1}
set.seed(1)
population <- rnorm(1000000, 10, 2)
(mu <- mean(population))
(mu_hat <- map_dbl(1:200, ~mean(sample(population, 100))) %>% mean())
```

How close is a single estimate? In general we answer this by computing the **standard error** of μ̂, written Se(μ̂). This is `σ/sqrt(n)`, where sigma is the population standard mean. The population deviation is seldom known, so the standard error of the mean is usually estimated as the **sample standard deviation**.

The standard error estimate is known as the **residual standard error**, and is given by the formula `RSE = sqrt(RSS / (n - 2))`. 

Using our previous generated values of `y_i` and `y_hat_i`, lets calculate the RSE:
```{r 3.2.1_2}
RSE <- sqrt( (sum((y_i - y_hat_i)^2)) / (length(y_i) - 2) )
RSE
```

The standard error can be used to calculate confidence intervals. A 95% confidence interval is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameter, or that it is within 2 standard deviations of the mean. Therefore the 95% confidence interval is 2 * SE(β̂ _1) and 2 * SE(β̂ _0).

#### Hypothesis Tests

The standard errors are used to perform hypothesis tests. The most common is the null hypothesis `H_0` - 'there is no relationship between `X` and `Y` versus the *alternative hypthesis* - there is some relationship between `X` and `Y`' (H_a : β_1  = 0). 

To test the null hypothesis, we need to derermine with the coefficient estimate is sufficiently far from zero that we can be confident that it's non-zero. How far is far enough? This depends on the accuracy of the coefficient.

* If the standard error is small, then even small values of the coefficient may be strong evidence against the null hypothesis.
* If the stanard error is large, the coefficient must be large  in absolute value in order for us to reject the null hypothesis.

In practice, a **t-statistic** is calculated, where `t = β̂_1- 0 / SE(β̂_1)`

This measures how many standard deviations the coefficient is away from 0. If there is no relationship, then we expect that the formula will have a **t-distribution** with n - 2 degrees of freedom.

Consequently it is simple to compute the probability of observing any value equal to |t| or larger, assuming β̂_1 = 0. We call this probability the **p-value**. Roughtly speaking, we interpret the p-value as follows: *a small p-value indicates that it is unlikely to observe such a substantial association between the predictor and the response due to chance.

If we see a small p-value, then we can infer ther is an association between the predictor and the response. We *reject the null hypothesis*. Typical p-value cutoffs for rejecting the null hypothesis are 5% or 1%. When n = 30, these correspond to t-statistics of around 2 and 2.75 respectively.

### 3.1.3 - Assessing the Accuracy of the Model

The quality of the model
